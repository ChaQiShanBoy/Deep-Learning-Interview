{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度学习 | 第十章 序列建模：循环和递归网络\n",
    "\n",
    ">深度学习领域圣经，英文原版的三位作者 Ian Goodfellow、Yoshua Bengio 和 Aaron Courville \n",
    "\n",
    "本人仅对中文版深度学习书中，提炼笔记，添加个人理解，该笔记仅作为个人深度学习知识的学习、总结、复习使用。若有错误，还望批评指教。----ZJ\n",
    "\n",
    "中文版 2017-09-04 版 pdf \n",
    "\n",
    "第十章内容：中文版 P318 -，英文版 P374 -\n",
    "\n",
    "Chapter 10 Sequence Modeling: Recurrent and Recursive Nets\n",
    "\n",
    "---\n",
    "\n",
    "**引子：**\n",
    "\n",
    "- **循环神经网络**（recurrent neural network）或 RNN (Rumelhart et al., 1986c)\n",
    "是一类用于处理**序列数据**的神经网络。\n",
    "\n",
    "- 卷积网络是专门用于处理**网格化数据** $\\rm X$（如一个图像）的神经网络，循环神经网络是专门用于处理**序列** $x^{(1)}, \\dots, x^{(\\tau)}$ 的神经网络。\n",
    "\n",
    "从多层网络出发到循环网络，我们需要利用上世纪 80 年代机器学习和统计模\n",
    "型早期思想的优点：**在模型的不同部分共享参数。参数共享使得模型能够扩展到不同形式的样本（这里指不同长度的样本）并进行泛化**。\n",
    "\n",
    "(如果我们在每个时间点都有一个单独的参数，我们不但不能泛化到训练时没有见过序列长度，也不能在时间上共享不同序列长度和不同位置的统计强度。)\n",
    "\n",
    "当信息的特定部分会在序列内多个位置出现时，这样的共享尤为重要。\n",
    "\n",
    "**例子：**\n",
    "\n",
    "- “I went to Nepal in 2009’’\n",
    "- “In 2009, I went to Nepal.”\n",
    "\n",
    "目的：们让一个机器学习模型读取这两个句子，并提取叙述者去Nepal的年份，无论 “2009 年’’ 是作为句子的第六个单词还是第二个单词出现，我们都希望模型能认出 “2009 年’’ 作为相关资料片段。\n",
    "\n",
    "假设我们要训练一个处理固定长度句子的前馈网络。**传统的全连接前馈网络**会给每个输入特征分配**一个单独的参数**，所以需要分别学习句子每个位置的所有语言规则。相比之下，**循环神经网络在几个时间步内共享相同的权重**，**不需要分别学习句子每个位置的所有语言规则。**\n",
    "\n",
    "**循环神经网络**以不同的方式**共享参数**。**输出的每一项是前一项的函数**。输出的每一项对先前的输出应用相同的更新规则而产生。这种循环方式导致参数通过很深的计算图共享。\n",
    "\n",
    "为简单起见，我们说的 **RNN 是指在序列上的操作**，并且该序列在时刻 t（从1 到 $τ$）包含向量 $x^{(t)}$。在实际情况中，循环网络通常在序列的小批量上操作，并且小批量的每项具有不同序列长度 $τ$。我们省略了小批量索引来简化记号。此外，时间步索引不必是字面上现实世界中流逝的时间。有时，它仅表示序列中的位置。\n",
    "\n",
    "---\n",
    "### <font color=\"#0099ff\">10.1 展开计算图\n",
    "\n",
    "**计算图是形式化一组计算结构的方式**，如那些涉及将输入和参数映射到输出和损失的计算。\n",
    "\n",
    "我们对 展开（unfolding）递归或循环计算得到的重复结构进行解释，这些重复结构通常对应于一个事件链。 展开（unfolding）这个计算图将导致深度网络结构中的参数共享。\n",
    "\n",
    "**动态系统的经典形式：**\n",
    "\n",
    "$$s^{(t)} = f(s^{(t-1)};\\theta)\\tag{10.1}$$\n",
    "\n",
    "- $s^{(t)} $,称为系统的状态。\n",
    "\n",
    "s 在时刻 t 的定义需要参考时刻 t − 1 时同样的定义，因此式(10.1)是循环的。\n",
    "\n",
    "\n",
    "循环神经网络可以通过许多不同的方式建立。就像几乎所有函数都可以被认为\n",
    "是前馈网络，本质上任何涉及循环的函数都可以被认为是一个循环神经网络。\n",
    "\n",
    "\n",
    "函数 g (t) 将全部的过去序列 (x (t) ,x (t−1) ,x (t−2) ,...,x (2) ,x (1) ) 作为输入来生成当前状态，但是展开的循环架构允许我们将 g (t) 分解为函数 f 的重复应用。因此，展开过程引入两个主要优点：\n",
    "\n",
    "1. 无论序列的长度，学成的模型始终具有相同的输入大小，因为它指定的是从一种状态到另一种状态的转移，而不是在可变长度的历史状态上操作。\n",
    "2. 我们可以在每个时间步使用相同参数的相同转移函数 f。\n",
    "\n",
    "\n",
    "这两个因素使得学习在所有时间步和所有序列长度上操作单一的模型 f 是可能的，\n",
    "而不需要在所有可能时间步学习独立的模型 g (t) 。学习单一的共享模型允许泛化到\n",
    "没有见过的序列长度（没有出现在训练集中），并且估计模型所需的训练样本远远少\n",
    "于不带参数共享的模型。\n",
    "\n",
    "---\n",
    "### <font color=\"#0099ff\">10.2\n",
    "\n",
    "\n",
    "循环神经网络中一些重要的设计模式包括以下几种：\n",
    "\n",
    "1. 每个时间步都有输出，并且隐藏单元之间有循环连接的循环网络，如图10.3所示。\n",
    "2. 每个时间步都产生一个输出，只有当前时刻的输出到下个时刻的隐藏单元之间有循环连接的循环网络，如图10.4所示。\n",
    "3. 隐藏单元之间存在循环连接，但读取整个序列后产生单个输出的循环网络，如图10.5所示。\n",
    "\n",
    "![](./images/10_4.png)\n",
    "\n",
    "\n",
    "现在我们研究图10.3中 RNN 的前向传播公式。这个图没有指定隐藏单元的激\n",
    "活函数。我们假设使用双曲正切激活函数。此外，图中没有明确指定何种形式的输出和损失函数。我们假定输出是离散的，如用于预测词或字符的 RNN。表示离散变量的常规方式是把输出 o 作为每个离散变量可能值的非标准化对数概率。然后，我们可以应用 softmax 函数 后续处理后，获得标准化后概率的输出向量 ˆ y。RNN 从特定的初始状态 h (0) 开始前向传播。从 t = 1 到 t = τ 的每个时间步，我们应用以下更新方程：\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "### <font color=\"#0099ff\">10.3\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "### <font color=\"#0099ff\">10.4\n",
    "\n",
    "\n",
    "---\n",
    "### <font color=\"#0099ff\">10.5\n",
    "\n",
    "\n",
    "---\n",
    "### <font color=\"#0099ff\">10.6\n",
    "\n",
    "\n",
    "---\n",
    "### <font color=\"#0099ff\">10.7\n",
    "\n",
    "\n",
    "---\n",
    "### <font color=\"#0099ff\">10.8\n",
    "\n",
    "\n",
    "---\n",
    "### <font color=\"#0099ff\">10.9\n",
    "\n",
    "\n",
    "---\n",
    "### <font color=\"#0099ff\">10.10\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "### <font color=\"#0099ff\">10.11\n",
    "\n",
    "\n",
    "---\n",
    "### <font color=\"#0099ff\">10.12\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
