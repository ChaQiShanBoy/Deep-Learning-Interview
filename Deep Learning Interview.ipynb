{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep-Learning-Interview_Part_1\n",
    "\n",
    ">本文原作者Jin Lee，本文来源于知乎专栏。\n",
    "问题集： https://zhuanlan.zhihu.com/p/29936999\n",
    "回答及对应英文页标：https://zhuanlan.zhihu.com/p/29965072\n",
    "elviswf 对上述问题找到 中文版对应页码。github 地址：[那些深度学习《面试》你可能需要知道的（中文页标版）](https://github.com/elviswf/DeepLearningBookQA_cn) https://github.com/elviswf/DeepLearningBookQA_cn\n",
    "\n",
    "----\n",
    "\n",
    "*本人以自身学习，加强基础知识为目的，查漏补缺。将对应页面知识，进行复习，学习，总结提炼。---ZJ*\n",
    "\n",
    "深度学习中文版 2017 年 9 月 4 日版\n",
    "\n",
    "#### 1. 列举常见的一些范数及其应用场景，如 L0，L1，L2，L∞，Frobenius 范数\n",
    "\n",
    "答：书内页面\n",
    "【英】p39-p40 ；还有p230-p236 有 regularization的应用 \n",
    "【中】p34-p35 ；还有 p197-p208 有 regularization 的应用\n",
    "\n",
    " **2.5 范数** （chrome 打开 pdf ----P62 chrome 上面统计的页数）\n",
    " \n",
    "有时我们需要衡量一个向量的大小。在机器学习中，我们经常使用被称为 范数（norm）的函数衡量向量大小。形式上，$L^p$ 范数定义如下\n",
    "\n",
    "$$||x||_p = (\\sum_{i}|x_{i}|^p)^{\\frac{1}{p}}\\tag{2.30} $$\n",
    "\n",
    "其中  $p ∈\\mathbb{R}，p ≥ 1$。\n",
    "\n",
    "范数（包括 $L^p$ 范数）是将向量映射到非负值的函数。 直观上来说，向量 $x$ 的范数衡量从原点到点 $x$ 的距离。 更严格地说，范数是满足下列性质的任意函数：\n",
    "\n",
    "- $f(x) = 0 \\Rightarrow x = \\mathbf{0}$\n",
    "- $f(x + y) \\leq f(x) + f(y)$ （三角不等式）\n",
    "- $\\forall \\alpha \\in \\mathbb{R}$, $f(\\alpha x) =\t\\alpha\tf(x)$\n",
    "\n",
    "当$p=2$时，$L^2$范数被称为欧几里得范数。 它表示从原点出发到向量 $x$ 确定的点的欧几里得距离。 $L^2$范数在机器学习中出现地十分频繁，经常简化表示为$||x||$，略去了下标$2$。 平方$L^2$范数也经常用来衡量向量的大小，可以简单地通过点积 $x^Tx$计算。\n",
    "\n",
    "平方$L^2$范数在数学和计算上都比$L^2$范数本身更方便。 例如，平方$L^2$范数对$x$中每个元素的导数只取决于对应的元素，而$L^2$范数对每个元素的导数却和整个向量相关。 但是在很多情况下，平方$L^2$范数也可能不受欢迎，因为它在原点附近增长得十分缓慢。 在某些机器学习应用中，区分恰好是零的元素和非零但值很小的元素是很重要的。 在这些情况下，我们转而使用在各个位置斜率相同，同时保持简单的数学形式的函数：$L^1$范数。 $L^1$范数可以简化如下：\n",
    "\n",
    "$$\\lVert{x}_1\\rVert = \\sum_i  |x_i|.\\tag{2.31}$$\n",
    "\n",
    "\n",
    "当机器学习问题中零和非零元素之间的差异非常重要时，通常会使用 $L^1$ 范数。 每当$x$中某个元素从 $0$ 增加 $\\epsilon$，对应的$L^1$范数也会增加 $\\epsilon$。\n",
    "\n",
    "有时候我们会统计向量中非零元素的个数来衡量向量的大小。 有些作者将这种函数称为”$L^0$范数”，但是这个术语在数学意义上是不对的。 向量的非零元素的数目不是范数，因为对向量缩放$\\alpha$倍不会改变该向量非零元素的数目。 $L^1$范数经常作为表示非零元素数目的替代函数。\n",
    "\n",
    "另外一个经常在机器学习中出现的范数是$L^\\infty$范数，也被称为\\,最大范数。 这个范数表示向量中具有最大幅值的元素的绝对值：\n",
    "\n",
    "$$  \\lVert{x}_1\\rVert _\\infty = \\max_i |x_i|.\\tag{2.32}$$\n",
    "\n",
    "有时候我们可能也希望衡量矩阵的大小。 在深度学习中，最常见的做法是使用 Frobenius 范数，\n",
    "\n",
    " $$\\lVert A \\rVert_F= \\sqrt{\\sum_{i,j} A_{i,j}^2}, $$\n",
    "\n",
    "\n",
    "其类似于向量的$L^2$范数。\n",
    "\n",
    "两个向量的点积可以用范数来表示。 具体地，\n",
    "\n",
    "$$  x^{\\mathrm{T}}y =\\lVert{x}\\rVert_2\\lVert{Y}\\rVert_2 \\cos \\theta\\tag{2.34}$$\n",
    "\n",
    "其中 $\\theta$ 表示 $x$ 和 $y$ 之间的夹角。\n",
    "\n",
    "---\n",
    "\n",
    "**第七章 深度学习中的正则化** （chrome 打开 pdf ----225 ）\n",
    "\n",
    "\n",
    "#### 2. 简单介绍一下贝叶斯概率与频率派概率，以及在统计中对于真实参数的假设。\n",
    "\n",
    "答：p35\n",
    "\n",
    "#### 3. 概率密度的万能近似器\n",
    "\n",
    "答：p43：3.10 上面那一段\n",
    "\n",
    "#### 4. 简单介绍一下 sigmoid，relu，softplus，tanh，RBF 及其应用场景\n",
    "\n",
    "答：sigmoid 和 softplus 在 p43 页；全部的在 p123-p127\n",
    "\n",
    "#### 5.Jacobian，Hessian 矩阵及其在深度学习中的重要性\n",
    "\n",
    "答：p56-p62\n",
    "\n",
    "#### 6.KL 散度在信息论中度量的是那个直观量\n",
    "\n",
    "答：p46\n",
    "\n",
    "#### 7. 数值计算中的计算上溢与下溢问题，如 softmax 中的处理方式\n",
    "\n",
    "答：p52-p53\n",
    "\n",
    "#### 8. 与矩阵的特征值相关联的条件数 (病态条件) 指什么，与梯度爆炸与梯度弥散的关系\n",
    "\n",
    "答：p53;\n",
    "\n",
    "#### 9. 在基于梯度的优化问题中，如何判断一个梯度为 0 的零界点为局部极大值／全局极小值还是鞍点，Hessian 矩阵的条件数与梯度下降法的关系\n",
    "\n",
    "答：p56-p62\n",
    "\n",
    "#### 10.KTT 方法与约束优化问题，活跃约束的定义\n",
    "\n",
    "答：p60-p61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
