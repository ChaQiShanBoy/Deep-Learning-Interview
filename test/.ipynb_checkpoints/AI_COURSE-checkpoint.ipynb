{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 人工智能初步\n",
    "\n",
    "    人工智能课程初稿\n",
    "    作者：赵君君\n",
    "    日期：2018-03-19\n",
    "\n",
    "\n",
    "## 第一部分 引言/绪论\n",
    "\n",
    "### 第一章 人工智能简介\n",
    "\n",
    "   - 1.1 人工智能的概念\n",
    "   \n",
    "       - 1.1.1 人工智能\n",
    "       - 1.1.2 机器学习\n",
    "       - 1.1.3 深度学习\n",
    "       \n",
    "   - 1.2 人工智能的基本特征\n",
    "   - 1.3 人工智能的发展历史\n",
    "       - 机器学习历史\n",
    "       - 深度学习历史\n",
    "   - 1.4 人工智能的典型应用与趋势\n",
    "       - 1.4.1 计算机视觉 \n",
    "       - 1.4.2 自然语言处理\n",
    "       - 1.4.3 语音处理\n",
    "       - 1.4.4 机器学习\n",
    "\n",
    "## 第二部分 人工智能核心算法\n",
    "\n",
    "### 第二章  线性代数基础\n",
    "\n",
    "   - 2.1 标量、向量、矩阵和张量 \n",
    "   - 2.3 矩阵和向量相乘\n",
    "   - 2.4 单位矩阵和逆矩阵\n",
    "   - 2.5 线性相关和生成子空间\n",
    "   - 2.6 范数\n",
    "   - 2.7 特殊类型的矩阵和向量\n",
    "   - 2.8 特征分解\n",
    "   - 2.9 奇异值分解\n",
    "   - 2.10 Moore-Penrose 伪逆\n",
    "   - 2.11 迹运算\n",
    "   - 2.12 行列式\n",
    "   - 2.13 实例：PCA 主成分分析 \n",
    "       \n",
    "### 第三章  概率与信息论基础\n",
    "\n",
    "   - 3.1 为什么要使用概率？\n",
    "   - 3.2 随机变量\n",
    "   - 3.3 概率分布\n",
    "   - 3.4 边缘概率\n",
    "   - 3.5 条件概率\n",
    "   - 3.6 条件概率的链式法则\n",
    "   - 3.7 独立性和条件独立性\n",
    "   - 3.8 期望、方差和协方差\n",
    "   - 3.9 常用概率分布\n",
    "   - 3.10 常用函数的有用性质\n",
    "   - 3.11 贝叶斯规则\n",
    "   - 3.12 连续型变量的技术细节\n",
    "   - 3.13 信息论\n",
    "   - 3.14 结构化概率模型\n",
    "\n",
    "### 第四章  Python 语言基础\n",
    "   \n",
    "   - 4.1 基础语法\n",
    "   - 4.2 基本数据类型\n",
    "   - 4.3 运算符与表达式\n",
    "   - 4.4 控制流\n",
    "   - 4.5 函数\n",
    "   - 4.6 模块\n",
    "   - 4.7 数据结构\n",
    "       - 列表\n",
    "       - 元组\n",
    "       - 字典\n",
    "   - 4.8 面向对象编程\n",
    "   - 4.9 输入与输出\n",
    "   - 4.10 异常\n",
    "   - 4.11 标准库\n",
    "   \n",
    "\n",
    "### 第五章 机器学习算法\n",
    "   \n",
    "   - 5.1 K-近邻算法：手写识别系统\n",
    "   - 5.2 决策树\n",
    "       - 5.2.1 基本流程\n",
    "       - 5.2.2 划分选择\n",
    "       - 5.2.3 剪枝处理\n",
    "       - 5.2.4 连续与缺失值\n",
    "       - 5.2.5 多变量与决策树\n",
    "       - 5.2.6 示例：使用决策树预测隐形眼镜类型 \n",
    "              \n",
    "   - 5.3 神经网络\n",
    "       - 5.3.1 神经元模型\n",
    "       - 5.3.2 感知机与多层网络\n",
    "       - 5.3.3 误差逆传播算法\n",
    "       - 5.3.4 全局最小与局部极小\n",
    "       - 5.3.5 其他常见神经网络\n",
    "       - 5.3.6 示例：Logistic 回归-从疝气病症预测病马死亡率\n",
    "       \n",
    "   - 5.4 支持向量机\n",
    "       - 5.4.1 间隔与支持向量\n",
    "       - 5.4.2 对偶问题\n",
    "       - 5.4.3 核函数\n",
    "       - 5.4.4 软间隔与正则化\n",
    "       - 5.4.5 支持向量回归\n",
    "       - 5.4.6 核方法\n",
    "       - 5.4.7 示例：手写识别问题优化\n",
    "       - \n",
    "   - 5.5 贝叶斯分类\n",
    "       - 5.5.1 贝叶斯决策轮\n",
    "       - 5.5.2 极大似然估计\n",
    "       - 5.5.3 朴素贝叶斯分类器\n",
    "       - 5.5.4 半朴素贝叶斯分类器\n",
    "       - 5.5.5 贝叶斯网\n",
    "       - 5.5.6 EM 算法\n",
    "       - 5.5.7 示例：使用朴素贝叶斯从个人广告中获取区域倾向\n",
    "       \n",
    "       \n",
    "........ (是否更多 待定)      \n",
    "\n",
    "### 第六章 深度学习\n",
    "\n",
    "   - 6.1 深度前网络\n",
    "       - 6.1.1 实例：学习 XOR\n",
    "       - 6.1.2 基于梯度的学习\n",
    "       - 6.1.3 隐藏单元\n",
    "       - 6.1.4 架构设计\n",
    "       - 6.1.5 反向传播和其他的微分算法\n",
    "       - 6.1.6 历史小记\n",
    "       \n",
    "   - 6.2 深度学习中的正则化\n",
    "       - 6.2.1 参数范数惩罚\n",
    "       - 6.2.2 作为约束的范数惩罚\n",
    "       - 6.2.3 正则化和欠约束问题\n",
    "       - 6.2.4 数据集增强\n",
    "       - 6.2.5 噪声鲁棒性\n",
    "       - 6.2.6 半监督学习\n",
    "       - 6.2.7 多任务学习\n",
    "       - 6.2.8 提前终止\n",
    "       - 6.2.9 参数绑定和参数共享\n",
    "       - 6.2.10 稀疏表示\n",
    "       - 6.2.11 Bagging 和其他集成方法\n",
    "       - 6.2.12 Dropout\n",
    "       - 6.2.13 对抗训练\n",
    "       - 6.2.14 切面距离、正切传播和流形正切分类器\n",
    "       \n",
    "   - 6.3 深度模型中的优化\n",
    "       - 6.3.1 学习和纯优化有什么不同\n",
    "       - 6.3.2 神经网络优化中的挑战\n",
    "       - 6.3.3 基本算法\n",
    "       - 6.3.4 参数初始化策略\n",
    "       - 6.3.5 自适应学习率算法\n",
    "       - 6.3.6 二阶近似方法\n",
    "       - 6.3.7 优化策略和元算法\n",
    "       \n",
    "（6.2 6.3 比较深入，可以省略，简单带过）\n",
    "\n",
    "   - 6.4 卷积网络\n",
    "       - 6.4.1 卷积运算\n",
    "       - 6.4.2 动机\n",
    "       - 6.4.3 池化\n",
    "       - 6.4.4 卷积与池化作为一种无限强的先验\n",
    "       - 6.4.5 基本卷积函数的变体\n",
    "       - 6.4.6 结构化输出\n",
    "       - 6.4.7 数据类型\n",
    "       - 6.4.8 高效的卷积算法\n",
    "       - 6.4.9 随机或无监督的特征\n",
    "       - 6.4.10 卷积网络的神经科学基础\n",
    "       - 6.4.11 卷积网络与深度学习的历史\n",
    "       - 6.4.12 开源框架 Tensorflow 实现：猫识别，人脸识别\n",
    "       \n",
    "   - 6.5 序列建模：循环和递归网络\n",
    "       - 6.5.1 展开计算图\n",
    "       - 6.5.2 循环神经网络\n",
    "       - 6.5.3 双向 RNN\n",
    "       - 6.5.4 基于编码-解码的序列到序列架构\n",
    "       - 6.5.5 深度循环网络\n",
    "       - 6.5.6 递归神经网络\n",
    "       - 6.5.7 长期依赖的挑战\n",
    "       - 6.5.8 回声状态网络\n",
    "       - 6.5.9 渗漏单元和其他多时间尺度的策略\n",
    "       - 6.5.10 长短期记忆和其他门控 RNN\n",
    "       - 6.5.11 优化长期依赖\n",
    "       - 6.5.12 外显记忆\n",
    "       - 开源框架 Tensorflow 实现：莎士比亚风格文本生成、音乐生成\n",
    "       \n",
    "    - 6.6 深度解读 AlphaGo 算法原理\n",
    "    - 6.7 开源框架介绍\n",
    "                    \n",
    "\n",
    "### 第七章 智能化社会面临的伦理及安全挑战\n",
    "\n",
    "   - 7.1 体验智能应用系统\n",
    "   - 7.2 智能化社会面临的伦理及安全挑战\n",
    "   - 7.3 信息系统安全的基本方法和措施\n",
    "   - 7.4 增强安全防护意识和责任感\n",
    "\n",
    "### 第八章 人工智能社会化应用的法律法规\n",
    "\n",
    "   - 8.1 辩证认识人工智能对人类社会发展的影响\n",
    "   - 8.2 自觉维护和遵守人工智能化社会应用的规范与法规\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
